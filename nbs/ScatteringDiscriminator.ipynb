{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37f03e62-0f76-45d3-b4ca-4364b5af960e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp discriminator\n",
    "from nbdev.showdoc import *\n",
    "import numpy as np\n",
    "from tqdm.notebook import trange, tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch_geometric\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a481eeb9-b4b2-47f8-8753-2a7cffd4c815",
   "metadata": {},
   "source": [
    "# Scattering Discriminator\n",
    "> Classify graphs as belonging to our dataset (or not) using a scattering network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9876ee2a-ebf2-41ed-bd01-ab6e236fdb5f",
   "metadata": {},
   "source": [
    "FEARFRED's generator creates and samples from a flow field. The Flashlight Kernel converts these samples into a directed graph. At last, we arrive at the final piece in our architecture: a GNN to discriminate between graphs coming from our dataset and graphs coming from the flow field. \n",
    "\n",
    "The trick here is to preserve the chain of differentiability between the generator and discriminator. This makes any translation of the affinity matrix from the flashlight kernel into a PyTorch Geometric format problematic -- this translation isn't differentiable! It's better to stay as close to the affinity matrix as possible.\n",
    "\n",
    "To do this, we adopt a *learnable scattering network*, LEGSNet, which operates entirely on the affinity matrix of a graph. This instatiation of LEGSNet uses the scattering transform as our *witness function*, paired with a simple feedforward classifier to make the final call on in-group membership."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16977c39-53e4-4096-b015-5b4d627bfff1",
   "metadata": {},
   "source": [
    "# Fixed LEGS Module\n",
    "Adapted from Alex Tong's LEGSNet, this module implements a vanilla scattering network on an adjacency matrix and degree information. In this simpler discriminator, there are no learnable parameters in the scattering transform -- only in the classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89b568f8-cc7d-4011-ac9f-a9e8ca5637a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def scatter_moments(data, moments_returned=2):\n",
    "    # given a matrix of node features of shape n_nodes x n_features, \n",
    "    # returns a vector of length moments_returned x n_features comprising the mean and \n",
    "    # variance of each feature\n",
    "    statistical_moments = {\"mean\": torch.zeros(0)}\n",
    "    if moments_returned >= 2:\n",
    "        statistical_moments[\"variance\"] = torch.zeros(0)\n",
    "    if moments_returned >= 3:\n",
    "        statistical_moments[\"skew\"] = torch.zeros(0)\n",
    "    if moments_returned >= 4:\n",
    "        statistical_moments[\"kurtosis\"] = torch.zeros(0)\n",
    "    def m(i):  # ith moment, computed with derivation data\n",
    "        return torch.mean(deviation_data ** i, axis=1)\n",
    "    mean = torch.mean(data, dim=1, keepdim=True)\n",
    "    if moments_returned >= 1:\n",
    "        statistical_moments[\"mean\"] = torch.cat(\n",
    "            (statistical_moments[\"mean\"], mean.T), dim=0\n",
    "        )\n",
    "    deviation_data = data - mean\n",
    "    # variance: difference of u and u mean, squared element wise, summed and divided by n-1\n",
    "    variance = m(2)\n",
    "    if moments_returned >= 2:\n",
    "        statistical_moments[\"variance\"] = torch.cat(\n",
    "            (statistical_moments[\"variance\"], variance[None, ...]), dim=0\n",
    "        )\n",
    "\n",
    "    # skew: 3rd moment divided by cubed standard deviation (sd = sqrt variance), with correction for division by zero (inf -> 0)\n",
    "    skew = m(3) / (variance ** (3 / 2))\n",
    "    skew[\n",
    "        skew > 1000000000000000\n",
    "    ] = 0  # multivalued tensor division by zero produces inf\n",
    "    skew[\n",
    "        skew != skew\n",
    "    ] = 0  # single valued division by 0 produces nan. In both cases we replace with 0.\n",
    "    if moments_returned >= 3:\n",
    "        statistical_moments[\"skew\"] = torch.cat(\n",
    "            (statistical_moments[\"skew\"], skew[None, ...]), dim=0\n",
    "        )\n",
    "\n",
    "    # kurtosis: fourth moment, divided by variance squared. Using Fischer's definition to subtract 3 (default in scipy)\n",
    "    kurtosis = m(4) / (variance ** 2) - 3\n",
    "    kurtosis[kurtosis > 1000000000000000] = -3\n",
    "    kurtosis[kurtosis != kurtosis] = -3\n",
    "    if moments_returned >= 4:\n",
    "        statistical_moments[\"kurtosis\"] = torch.cat(\n",
    "            (statistical_moments[\"kurtosis\"], kurtosis[None, ...]), dim=0\n",
    "        )\n",
    "    # Concatenate into one tensor (alex)\n",
    "    # statistical_moments = torch.cat([v for k,v in statistical_moments.items()], axis=1)\n",
    "    statistical_moments = torch.cat([statistical_moments['mean'],statistical_moments['variance']],axis=1)\n",
    "    return statistical_moments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1767fb2e-9d37-4503-8fe1-35554858c6db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data is  tensor([[0.2874, 0.3005, 0.7480],\n",
      "        [0.7218, 0.2515, 0.1180],\n",
      "        [0.7301, 0.9778, 0.3636],\n",
      "        [0.1182, 0.1867, 0.6095],\n",
      "        [0.7845, 0.1892, 0.8575]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0.4453, 0.3638, 0.6905, 0.3048, 0.6104, 0.0458, 0.0671, 0.0637, 0.0472,\n",
       "         0.0896]])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = torch.rand(5,3)\n",
    "print(\"data is \",data)\n",
    "scatter_moments(data,moments_returned=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dc1ebbe-0fb3-4c94-bdc5-69999938535c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "class ScatteringDiscriminator(nn.Module):\n",
    "    \"\"\"\n",
    "    Given an affinity matrix and associated node features, classifies: \n",
    "    does this belong to the true dataset?\n",
    "    The number of nodes per graph must be constant.\n",
    "    \"\"\"\n",
    "    def __init__(self, \n",
    "                 n_nodes, # number of nodes in inputted graphs\n",
    "                 n_features # number of features per node\n",
    "                ):\n",
    "        super().__init__()\n",
    "        self.n_nodes = n_nodes \n",
    "        self.n_features = n_features\n",
    "        self.n_scattering_moments = 2\n",
    "        self.n_scattering_features = 11 * self.n_scattering_moments * self.n_features\n",
    "        self.classifier_l1 = nn.Linear(self.n_scattering_features, 128)\n",
    "        self.classifier_l2 = nn.Linear(128, 128)\n",
    "        self.classifier_l3 = nn.Linear(128, 128)\n",
    "        self.classifier_l4 = nn.Linear(128, 128)\n",
    "        self.classifier_l5 = nn.Linear(128, 64)\n",
    "        self.classifier_l6 = nn.Linear(64, 32)\n",
    "        self.classifier_l7 = nn.Linear(32, 16)\n",
    "        self.classifier_l8 = nn.Linear(16, 1)\n",
    "        \n",
    "    def diffuse(self,P, node_features):\n",
    "        # diffuses node features using diffusion matrix\n",
    "        # diffusion is left multiplication, equivalent to right multiplication by transpose\n",
    "        node_features_transposed = node_features.permute(*torch.arange(node_features.ndim - 1, -1, -1))\n",
    "        left_multiplication = node_features_transposed @ P\n",
    "        transposed_left_mult = left_multiplication.permute(*torch.arange(left_multiplication.ndim - 1, -1, -1))\n",
    "\n",
    "        return transposed_left_mult\n",
    "        # return P.T @ node_features\n",
    "    \n",
    "    def feng_filters(self):\n",
    "        tmp = np.arange(16).reshape(4,4)\n",
    "        results = [4]\n",
    "        for i in range(2, 4):\n",
    "            for j in range(0, i):\n",
    "                results.append(4*i+j)\n",
    "        return results\n",
    "    \n",
    "    def scattering_transform(self, A, node_features):\n",
    "        # Given an affinity matrix and node features, performs a wavelet transform\n",
    "        # Adapted from Alex Tong's LEGSNet code\n",
    "        # construct diffusion matrix\n",
    "        D = torch.sum(A,axis=1)\n",
    "        P = 1/2*torch.eye(len(A)) + 1/2*(A / D[:,None]) # TODO: ensure no self loops in A\n",
    "        # TODO: Could make laziness learnable.\n",
    "        # diffuse 16 times\n",
    "        avgs = [node_features[:,:,None]]\n",
    "        for i in range(16):\n",
    "            avgs.append(self.diffuse(P, avgs[i]))\n",
    "        # diffusion wavelets at various levels\n",
    "        filter1 = avgs[1] - avgs[2]\n",
    "        filter2 = avgs[2] - avgs[4]\n",
    "        filter3 = avgs[4] - avgs[8]\n",
    "        filter4 = avgs[8] - avgs[16]\n",
    "        # print('filter shape',filter4.shape)\n",
    "        # print('avg shape',avgs[1].shape)\n",
    "        s0 = avgs[0]\n",
    "        # the all-important nonlinearity\n",
    "        s1 = torch.abs(torch.cat([filter1, filter2, filter3, filter4], dim=-1))\n",
    "        # s1 is the set of scattering features for the graph\n",
    "        # print('s1 shape is ',s1.shape)\n",
    "        # repeat a second time\n",
    "        avgs = [s1]\n",
    "        for i in range(16):\n",
    "            avgs.append(self.diffuse(P, avgs[i]))\n",
    "        filter1 = avgs[1] - avgs[2]\n",
    "        filter2 = avgs[2] - avgs[4]\n",
    "        filter3 = avgs[4] - avgs[8]\n",
    "        filter4 = avgs[8] - avgs[16]\n",
    "        s2 = torch.abs(torch.cat([filter1, filter2, filter3, filter4], dim=-1))\n",
    "        # print(\"s2 fresh\",s2.shape)\n",
    "        s2_reshaped = torch.reshape(s2, (-1, self.n_features, 4))\n",
    "        # print(\"s2 after first reshape\",s2.shape)\n",
    "        s2 = torch.reshape(torch.transpose(s2_reshaped, 1, 2), (-1, 16, self.n_features))\n",
    "        # print(\"s2 after second reshape\",s2.shape)\n",
    "        s2 = s2[:, self.feng_filters()]\n",
    "        # print(\"s2 after feng filters\",s2.shape)\n",
    "        \n",
    "        x = torch.cat([s0, s1], dim=2)\n",
    "        # print(\"x shape merged s0 and s1\",x.shape)\n",
    "        x = torch.transpose(x, 1, 2)\n",
    "        # print(\"x shape transposed\",x.shape)\n",
    "        # print(\"s2 shape\",s2.shape)\n",
    "        x = torch.cat([x, s2], dim=1)\n",
    "        \n",
    "        # print(\"x shape into scatter moments\",x.shape)\n",
    "        # collapse features\n",
    "        x = x.reshape(11*self.n_features,self.n_nodes)\n",
    "        # print(\"x reshaped\",x.shape)\n",
    "\n",
    "        x = scatter_moments(x,moments_returned = self.n_scattering_moments)\n",
    "        # print(\"x shape out of scatter moments\",x.shape)\n",
    "\n",
    "        return x\n",
    "    \n",
    "    def classifier(self,scattering_features):\n",
    "        x = self.classifier_l1(scattering_features)\n",
    "        x = F.gelu(x)\n",
    "        x = self.classifier_l2(x)\n",
    "        x = F.gelu(x)\n",
    "        x = self.classifier_l3(x)\n",
    "        x = F.gelu(x)\n",
    "        x = self.classifier_l4(x)\n",
    "        x = F.gelu(x)\n",
    "        x = self.classifier_l5(x)\n",
    "        x = F.gelu(x)\n",
    "        x = self.classifier_l6(x)\n",
    "        x = F.gelu(x)\n",
    "        x = self.classifier_l7(x)\n",
    "        x = F.gelu(x)\n",
    "        x = self.classifier_l8(x)\n",
    "        return x\n",
    "        \n",
    "    def forward(self,A,node_features):\n",
    "        x = self.scattering_transform(A,node_features)\n",
    "        y = self.classifier(x)\n",
    "        return y        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aa013f3-13d2-489f-9958-130a567ba8a1",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "839800bb-3117-4f5c-8dde-75056610a760",
   "metadata": {},
   "outputs": [],
   "source": [
    "SD = ScatteringDiscriminator(n_nodes=42,n_features=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58034e64-19ba-48b2-a688-2368b55d2c99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.2413, 0.0148]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = torch.rand(42,42)\n",
    "x = torch.ones(42,2)\n",
    "SD(A,x)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:FEARFRED]",
   "language": "python",
   "name": "conda-env-FEARFRED-py"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
