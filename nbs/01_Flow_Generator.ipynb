{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fe4d8762-363a-4e27-a771-511ad28e9438",
   "metadata": {},
   "source": [
    "# 01 The Flow Generator of Directed Graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "566f214a-9150-4d88-bb15-7ed13771b162",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "#| default_exp generator\n",
    "from nbdev.showdoc import *\n",
    "import numpy as np\n",
    "import fastcore\n",
    "from tqdm.auto import trange, tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8b11ecd-ccd8-4b85-b890-38419ccedb9a",
   "metadata": {},
   "source": [
    "FEARFRED is built of three intertwingled components, two standard for a GAN, and one unique to its graph-embedding mission:\n",
    "\n",
    "- The Generator - creates and samples from a flow field, intended to model the directed graph\n",
    "- The Random Walkers - given a sample from the flow field, constructs a directed *sub*-graph with a gaggle of random walkers.\n",
    "- The GNN discriminator - given a directeed (sub)graph, classifies it as belonging to the ground truth data.\n",
    "\n",
    "This notebook defines and tests the Flow Generator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eacf668-597f-46cc-876a-fa6d919eaa47",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from fastcore.basics import *\n",
    "class FlowGenerator(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        dimension, # intrinsic dimension of the data manifold. Should be estimated prior to applying FEARFRED\n",
    "        n_features, # features per node\n",
    "        inner_dimension = 64,\n",
    "    ):\n",
    "        store_attr()\n",
    "        super().__init__()\n",
    "        # the flow artist creates the vector field\n",
    "        self.flow_artist_l1 = nn.Linear(self.dimension, 64)\n",
    "        self.flow_artist_l2 = nn.Linear(64, 64)\n",
    "        self.flow_artist_l3 = nn.Linear(64, 64)\n",
    "        self.flow_artist_l4 = nn.Linear(64, 64)\n",
    "        self.flow_artist_l5 = nn.Linear(64, 64)\n",
    "        self.flow_artist_l6 = nn.Linear(64, 64)\n",
    "        self.flow_artist_l7 = nn.Linear(64, 64)\n",
    "        self.flow_artist_l8 = nn.Linear(64, self.dimension)\n",
    "        # the flow sampler defines a distribution over the vector field, showing where in the space to sample from\n",
    "        self.flow_sampler_l1 = nn.Linear(self.dimension, 64)\n",
    "        self.flow_sampler_l2 = nn.Linear(64, 64)\n",
    "        self.flow_sampler_l3 = nn.Linear(64, 64)\n",
    "        self.flow_sampler_l4 = nn.Linear(64, 64)\n",
    "        self.flow_sampler_l5 = nn.Linear(64, 64)\n",
    "        self.flow_sampler_l6 = nn.Linear(64, 64)\n",
    "        self.flow_sampler_l7 = nn.Linear(64, 64)\n",
    "        self.flow_sampler_l8 = nn.Linear(64, self.dimension)\n",
    "        # the feature giver assigns features to each point in the embedding space\n",
    "        self.feature_giver_l1 = nn.Linear(self.dimension, 64)\n",
    "        self.feature_giver_l2 = nn.Linear(64, 64)\n",
    "        self.feature_giver_l3 = nn.Linear(64, 64)\n",
    "        self.feature_giver_l4 = nn.Linear(64, 64)\n",
    "        self.feature_giver_l5 = nn.Linear(64, 64)\n",
    "        self.feature_giver_l6 = nn.Linear(64, 64)\n",
    "        self.feature_giver_l7 = nn.Linear(64, 64)\n",
    "        self.feature_giver_l8 = nn.Linear(64, self.n_features)\n",
    "    def flow_artist(self,x):\n",
    "        # evaluates the vector field at point x\n",
    "        x = self.flow_artist_l1(x)\n",
    "        x = F.gelu(x)\n",
    "        x = self.flow_artist_l2(x)\n",
    "        x = F.gelu(x)\n",
    "        x = self.flow_artist_l3(x)\n",
    "        x = F.gelu(x)\n",
    "        x = self.flow_artist_l4(x)\n",
    "        x = F.gelu(x)\n",
    "        x = self.flow_artist_l5(x)\n",
    "        x = F.gelu(x)\n",
    "        x = self.flow_artist_l6(x)\n",
    "        x = F.gelu(x)\n",
    "        x = self.flow_artist_l7(x)\n",
    "        x = F.gelu(x)\n",
    "        x = self.flow_artist_l8(x)\n",
    "        x = torch.sigmoid(x)\n",
    "        return x\n",
    "    def flow_sampler(self,x):\n",
    "        # samples from the embedding space. Should be given inputs in [0,1]^n\n",
    "        x = self.flow_sampler_l1(x)\n",
    "        x = F.gelu(x)\n",
    "        x = self.flow_sampler_l2(x)\n",
    "        x = F.gelu(x)\n",
    "        x = self.flow_sampler_l3(x)\n",
    "        x = F.gelu(x)\n",
    "        x = self.flow_sampler_l4(x)\n",
    "        x = F.gelu(x)\n",
    "        x = self.flow_sampler_l5(x)\n",
    "        x = F.gelu(x)\n",
    "        x = self.flow_sampler_l6(x)\n",
    "        x = F.gelu(x)\n",
    "        x = self.flow_sampler_l7(x)\n",
    "        x = F.gelu(x)\n",
    "        x = self.flow_sampler_l8(x)\n",
    "        return x\n",
    "    def feature_giver(self,x):\n",
    "        x = self.feature_giver_l1(x)\n",
    "        x = F.gelu(x)\n",
    "        x = self.feature_giver_l2(x)\n",
    "        x = F.gelu(x)\n",
    "        x = self.feature_giver_l3(x)\n",
    "        x = F.gelu(x)\n",
    "        x = self.feature_giver_l4(x)\n",
    "        x = F.gelu(x)\n",
    "        x = self.feature_giver_l5(x)\n",
    "        x = F.gelu(x)\n",
    "        x = self.feature_giver_l6(x)\n",
    "        x = F.gelu(x)\n",
    "        x = self.feature_giver_l7(x)\n",
    "        x = F.gelu(x)\n",
    "        x = self.feature_giver_l8(x)\n",
    "        return x\n",
    "    def forward(self,samples):\n",
    "        points = self.flow_sampler(samples)\n",
    "        flows = self.flow_artist(points)\n",
    "        features = self.feature_giver(points)\n",
    "        return points,flows,features\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a236635-ef5e-43a0-bcaf-4d1e5d7c89c7",
   "metadata": {},
   "source": [
    "## Visualizing the output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32a183d9-dfde-4e7f-aee0-3d55465c364f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing to ensure it runs\n",
    "FG = FlowGenerator(dimension=2, n_features=1)\n",
    "points = FG.flow_sampler(torch.rand(50,2))\n",
    "flows = FG.flow_artist(points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90650c48-dae7-412e-b14f-6e78e3591db0",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'FEARFRED'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "Input \u001B[0;32mIn [4]\u001B[0m, in \u001B[0;36m<cell line: 2>\u001B[0;34m()\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m#| export\u001B[39;00m\n\u001B[0;32m----> 2\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mFEARFRED\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mplotting\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m plot_directed_2d, plot_flow_field_2d\n",
      "\u001B[0;31mModuleNotFoundError\u001B[0m: No module named 'FEARFRED'"
     ]
    }
   ],
   "source": [
    "#| export\n",
    "from FEARFRED.plotting import plot_directed_2d, plot_flow_field_2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e765079c-7751-42c6-a183-61649d1683b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_flow_field_2d(FG)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff7f3a93-00e7-49e8-82bb-6edfdfdbad6f",
   "metadata": {},
   "source": [
    "# Testing\n",
    "\n",
    "To examine the generative power of the `FlowGenerator`, here's a couple of simple tests, where we instruct it to recreate toy manifolds based on a direct penalty. Each will receive points and associated flows and penalize them for adherence to a toy manifold."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efa3d7e8-1464-4469-80f0-d383dc9353b8",
   "metadata": {},
   "source": [
    "## Can it learn a circle?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e167404e-fb3d-4836-aa14-95727e6a118a",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_samples = torch.rand(100,2)*2-1\n",
    "angles_of_samples = torch.norm(random_samples,dim=1)*2*torch.pi\n",
    "real_circle, real_flows = torch.zeros_like(random_samples), torch.zeros_like(random_samples)\n",
    "real_circle[:,0] = torch.cos(angles_of_samples)\n",
    "real_circle[:,1] = torch.sin(angles_of_samples)\n",
    "real_flows[:,0] = -torch.sin(angles_of_samples)\n",
    "real_flows[:,1] = torch.cos(angles_of_samples)\n",
    "plot_directed_2d(real_circle,real_flows,angles_of_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd000663-f007-4bf8-b29b-34ce1b5960e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def circle_loss(points, flows, features, random_samples):\n",
    "    loss = 0\n",
    "    # calculate angles of points \n",
    "    angles_of_samples = torch.norm(random_samples,dim=1)*2*torch.pi\n",
    "    real_circle, real_flows = torch.zeros_like(random_samples), torch.zeros_like(random_samples)\n",
    "    real_circle[:,0] = torch.cos(angles_of_samples)\n",
    "    real_circle[:,1] = torch.sin(angles_of_samples)\n",
    "    real_flows[:,0] = -torch.sin(angles_of_samples)\n",
    "    real_flows[:,1] = torch.cos(angles_of_samples)\n",
    "    # penalize all of the points to have distance 1 from the origin\n",
    "    loss += torch.linalg.norm(points - real_circle)\n",
    "    # penalize flows to be perpendicular to the points, i.e. have zero cosine similarity\n",
    "    loss += torch.sum(1-torch.abs(F.cosine_similarity(flows,real_flows)))\n",
    "    # penalize features to be the angles\n",
    "    loss += 0.01*torch.linalg.norm(features - angles_of_samples)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bda6304c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.datasets import MNIST\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "import os\n",
    "dataset = MNIST(os.getcwd(), download=True, transform=transforms.ToTensor())\n",
    "train_loader = DataLoader(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfc91bb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytorch_lightning as pl\n",
    "from torch import optim, nn, utils, Tensor\n",
    "import fastcore \n",
    "class FlowGenerator_trainer(pl.LightningModule):\n",
    "    def __init__(self,\n",
    "        dimension,\n",
    "        n_features,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        fastcore.basics.store_attr() # stores each input parameter 'blah' into 'self.blah', saving lots of code\n",
    "        self.FG = FlowGenerator(dimension, n_features)\n",
    "    def training_step(self, batch, batch_indices):\n",
    "        samples = torch.rand(128,2)\n",
    "        points, flows, features = self.FG(samples)    \n",
    "        loss = circle_loss(points,flows,features, samples)\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = optim.Adam(self.parameters(), lr=1e-3)\n",
    "        return optimizer\n",
    "    def visualize(self):\n",
    "        plot_flow_field_2d(self.FG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10df8a3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = FlowGenerator_trainer(\n",
    "    dimension=2,\n",
    "    n_features=1\n",
    ")\n",
    "trainer = pl.Trainer()\n",
    "trainer.fit(model, train_dataloaders=train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6422899-417b-4074-b812-4b2e6f459511",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = FlowGenerator(dimension=2,n_features=1)\n",
    "device = torch.device('cpu')\n",
    "model.to(device)\n",
    "opt = torch.optim.Adam(model.parameters()) \n",
    "train_accs, test_accs, losses = [], [], [] # lists to keep track of model stats\n",
    "for e in trange(2000): # this is the number of epochs to train -- each epoch iterates through the entire dataset.\n",
    "    model.train()\n",
    "    samples = torch.rand(128,2)\n",
    "    points, flows, features = model(samples)    \n",
    "    l = circle_loss(points,flows,features, samples)\n",
    "    l.backward()\n",
    "    opt.step()\n",
    "    opt.zero_grad()\n",
    "    losses.append(l.item())\n",
    "plt.plot(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "332997fa-3869-41d2-aeb0-0519249946df",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_flow_field_2d(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "752b048c-792f-45e9-b122-2c94889075d2",
   "metadata": {},
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daeac74d-7d51-4001-8cfd-60a69ca6f9cf",
   "metadata": {},
   "source": [
    "Yes, the generator can successfully learn the flow field and sampling strategy of a circle. Using 8 layers instead of 3 helped it learn with 10x less training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1cd6658-0b50-49ba-8de5-0cf8311daed0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:lighting]",
   "language": "python",
   "name": "conda-env-lighting-py"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
