{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d77087fb-5b45-4033-9c11-504e8c69478c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp gan\n",
    "from nbdev.showdoc import *\n",
    "import numpy as np\n",
    "from tqdm.notebook import trange, tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch_geometric\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "461a78dc-0439-48d5-ac1f-bb281bd22a67",
   "metadata": {},
   "source": [
    "# Directed Graph Embedding by GAN\n",
    "> Learning a flow field that, when sampled, matches a class of directed graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fabd435-733d-43e5-9fe9-eb5d4ec06b12",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from FEARFRED.generator import *\n",
    "from FEARFRED.discriminator import *\n",
    "from FEARFRED.graph_builder import *\n",
    "class FRED_A_GAN(nn.Module):\n",
    "    def __init__(self,\n",
    "                 intrinsic_dimension, # intrinsic dimension of data\n",
    "                 n_nodes, # number of nodes in directed subgraphs\n",
    "                 n_features, # number of features per node\n",
    "                ):\n",
    "        super().__init__()\n",
    "        self.intrinsic_dimension = intrinsic_dimension\n",
    "        self.n_nodes = n_nodes\n",
    "        self.n_features = n_features + 1 # we include an extra vector of 1s when feeding to the discriminator\n",
    "        # initialize GAN machineru\n",
    "        self.generator = FlowGenerator(self.intrinsic_dimension,n_features) # generates the actual number of featuers\n",
    "        self.discriminator = ScatteringDiscriminator(self.n_nodes,self.n_features)\n",
    "        \n",
    "    def generate_fake(self):\n",
    "        # 1. sample from the unit hypercube\n",
    "        # TODO: Could adjust this to sample from parts of the hypercube\n",
    "        # to get localized subgraphs\n",
    "        samples = torch.randn(self.n_nodes,self.intrinsic_dimension)\n",
    "        # 2. Translate to a sample in the embedding space, and take flows\n",
    "        points, flows, features = self.generator(samples)\n",
    "        # 3. construct a directed graph based off of these points and flows, \n",
    "        # and create summary node features for it\n",
    "        A = flashlight_kernel(points,flows,kernel_type='fixed', sigma=0.7)\n",
    "        # simplify graph with this nonlinearity\n",
    "        A[A<0.01] = 0\n",
    "        # TODO: Might have to revise that.\n",
    "        node_features = torch.ones(self.n_nodes,self.n_features).float()\n",
    "        node_features[:,1:] = features\n",
    "        return A, node_features\n",
    "    \n",
    "    def train_critic(self, A, features):\n",
    "        # generate a fake image and run it through the discriminator\n",
    "        fakeA, fake_features = self.generate_fake()\n",
    "        # detach gradients when training critic, to prevent unnecessary backprop graph construction\n",
    "        fakeA = fakeA.detach()\n",
    "        fake_features = fake_features.detach()\n",
    "        witness_of_fake = self.discriminator(fakeA,fake_features)\n",
    "        \n",
    "        # Test the critic on real data\n",
    "        node_features = torch.ones(self.n_nodes,self.n_features).float()\n",
    "        node_features[:,1:] = features\n",
    "        # Run through discriminator and compute loss\n",
    "        witness_of_real = self.discriminator(A,node_features)\n",
    "        # Loss is the difference between the witness function of fake and real\n",
    "        # The critic wants to maximize this difference\n",
    "        loss = witness_of_fake - witness_of_real\n",
    "        return loss\n",
    "        \n",
    "    def train_generator(self,A,features):\n",
    "        # 1. sample from the unit hypercube\n",
    "        # TODO: Could adjust this to sample from parts of the hypercube\n",
    "        # to get localized subgraphs\n",
    "        fakeA, fake_features = self.generate_fake()\n",
    "        # 4. Run the graph and its features through the discriminator\n",
    "        witness_of_fake = self.discriminator(fakeA,fake_features)\n",
    "        # generator wants to minimize the witness function on its data\n",
    "        loss = - witness_of_fake\n",
    "        return loss\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0650e2e9-a7f1-4971-8c75-33bd031ea6bb",
   "metadata": {},
   "source": [
    "Testing that it runs on fake data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3487d218-2af4-48ef-bee2-3bcc7adfd364",
   "metadata": {},
   "outputs": [],
   "source": [
    "A = torch.rand(10,10)\n",
    "features = torch.rand(10,2)\n",
    "fredtest = FRED_A_GAN(\n",
    "    intrinsic_dimension = 2,\n",
    "    n_nodes = 10,\n",
    "    n_features = 2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b550d7d0-ca4a-42ec-81df-aaa4ce7d68e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "l_g = fredtest.train_generator(A,features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73b94613-9575-4463-9184-f409d5d0ddbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "l_d = fredtest.train_critic(A,features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b7e4c61-ae4c-4cfa-a945-dca9ea891bcd",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b565b49-2ce9-479b-9e81-47d84236bfd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 500\n",
    "n_critic = 5 # number of times to train the critic for each training iteration of the generator\n",
    "weight_clipping_value = 0.01\n",
    "fred = FRED_A_GAN(\n",
    "    intrinsic_dimension = 2,\n",
    "    n_nodes = 128,\n",
    "    n_features = 1\n",
    ")\n",
    "opt_gen = torch.optim.Adam(fred.generator.parameters())\n",
    "opt_discrim = torch.optim.Adam(fred.discriminator.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecd09252-4e72-4c54-830f-f42b271e48f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from FEARFRED.datasets.manifolds import DirectedCircle\n",
    "from torch.utils.data import DataLoader\n",
    "d = DirectedCircle()\n",
    "dataloader = DataLoader(d, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d0cb602-eaff-4fa1-9b0d-f5360d7a3714",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cebefa74cefe4ccfb50ffb67ba664cb6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e10bd4134827404cbbacb82270885f2b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5e1b0cf761a47ec9f76bda94da81379",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "439142202b1b4feba767f33edc90e5e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "396a0a7899f543d1a5ff850f5f3d8583",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11dad85accef42ef8444e350c2944317",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39d8a4539d374c9abbacff7519f4ff4a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "970e8d8787554164bcdaf6fbdbc32def",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1083ba9d01c94e3d992c1c350f2a39a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[E thread_pool.cpp:113] Exception in thread pool task: mutex lock failed: Invalid argument\n",
      "[E thread_pool.cpp:113] Exception in thread pool task: mutex lock failed: Invalid argument\n",
      "[E thread_pool.cpp:113] Exception in thread pool task: mutex lock failed: Invalid argument\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [8], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m e \u001b[38;5;129;01min\u001b[39;00m trange(n_epochs):\n\u001b[1;32m      2\u001b[0m     i \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m----> 3\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m A, features \u001b[38;5;129;01min\u001b[39;00m tqdm(dataloader):\n\u001b[1;32m      4\u001b[0m         i \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m      5\u001b[0m         \u001b[38;5;66;03m# shape wrangling: presently each batch has but a single matrix and list of features\u001b[39;00m\n",
      "File \u001b[0;32m~/miniforge3/envs/FEARFRED/lib/python3.9/site-packages/tqdm/notebook.py:259\u001b[0m, in \u001b[0;36mtqdm_notebook.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    257\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    258\u001b[0m     it \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msuper\u001b[39m(tqdm_notebook, \u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__iter__\u001b[39m()\n\u001b[0;32m--> 259\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m it:\n\u001b[1;32m    260\u001b[0m         \u001b[38;5;66;03m# return super(tqdm...) will not catch exception\u001b[39;00m\n\u001b[1;32m    261\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m obj\n\u001b[1;32m    262\u001b[0m \u001b[38;5;66;03m# NB: except ... [ as ...] breaks IPython async KeyboardInterrupt\u001b[39;00m\n",
      "File \u001b[0;32m~/miniforge3/envs/FEARFRED/lib/python3.9/site-packages/tqdm/std.py:1195\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1192\u001b[0m time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_time\n\u001b[1;32m   1194\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1195\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m iterable:\n\u001b[1;32m   1196\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m obj\n\u001b[1;32m   1197\u001b[0m         \u001b[38;5;66;03m# Update and possibly print the progressbar.\u001b[39;00m\n\u001b[1;32m   1198\u001b[0m         \u001b[38;5;66;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniforge3/envs/FEARFRED/lib/python3.9/site-packages/torch/utils/data/dataloader.py:681\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    678\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    679\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    680\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 681\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    682\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    683\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    684\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    685\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/miniforge3/envs/FEARFRED/lib/python3.9/site-packages/torch/utils/data/dataloader.py:721\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    719\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    720\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 721\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    722\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    723\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/miniforge3/envs/FEARFRED/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py:49\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfetch\u001b[39m(\u001b[38;5;28mself\u001b[39m, possibly_batched_index):\n\u001b[1;32m     48\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauto_collation:\n\u001b[0;32m---> 49\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/miniforge3/envs/FEARFRED/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py:49\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfetch\u001b[39m(\u001b[38;5;28mself\u001b[39m, possibly_batched_index):\n\u001b[1;32m     48\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauto_collation:\n\u001b[0;32m---> 49\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/Projects/FEARFRED/FEARFRED/datasets/manifolds.py:382\u001b[0m, in \u001b[0;36mDirectedCircle.__getitem__\u001b[0;34m(self, i)\u001b[0m\n\u001b[1;32m    380\u001b[0m flows \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(flows)\n\u001b[1;32m    381\u001b[0m features \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(labels)\n\u001b[0;32m--> 382\u001b[0m A \u001b[38;5;241m=\u001b[39m \u001b[43mflashlight_kernel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflows\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkernel_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mfixed\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43msigma\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.7\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    383\u001b[0m \u001b[38;5;66;03m# threshold to top 10% of edges\u001b[39;00m\n\u001b[1;32m    384\u001b[0m A[A\u001b[38;5;241m<\u001b[39m\u001b[38;5;241m0.01\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "File \u001b[0;32m~/Projects/FEARFRED/FEARFRED/graph_builder.py:81\u001b[0m, in \u001b[0;36mflashlight_kernel\u001b[0;34m(X, flows, kernel_type, k, sigma, anisotropic_density_normalization, flow_strength)\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m flow_strength \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mint\u001b[39m(flow_strength) \u001b[38;5;129;01mand\u001b[39;00m flow_strength \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;241m!=\u001b[39m flow_strength \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m2\u001b[39m\n\u001b[1;32m     80\u001b[0m W_strengthened_cosine \u001b[38;5;241m=\u001b[39m W_cosine \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m flow_strength\n\u001b[0;32m---> 81\u001b[0m D \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinalg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnorm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mDA\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     82\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m kernel_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124manisotropic\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m     83\u001b[0m     W \u001b[38;5;241m=\u001b[39m anisotropic_kernel(D, sigma\u001b[38;5;241m=\u001b[39msigma, alpha\u001b[38;5;241m=\u001b[39manisotropic_density_normalization) \u001b[38;5;66;03m# works with pytorch tensors, is theoretically differentiable.\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for e in trange(n_epochs):\n",
    "    i = 0\n",
    "    for A, features in tqdm(dataloader):\n",
    "        i += 1\n",
    "        # shape wrangling: presently each batch has but a single matrix and list of features\n",
    "        A = A[0].float()\n",
    "        features = features[0][:,None] # reshape to n_nodes x n_features\n",
    "        features = features.float()\n",
    "        \n",
    "        opt_discrim.zero_grad()\n",
    "        loss = fred.train_critic(A, features)\n",
    "        loss.backward()\n",
    "        opt_discrim.step()\n",
    "        \n",
    "        for p in fred.discriminator.parameters():\n",
    "            p.data.clamp_(-weight_clipping_value, weight_clipping_value)\n",
    "\n",
    "        if i % n_critic == 0:\n",
    "            # Train generator\n",
    "            opt_gen.zero_grad()\n",
    "            loss = fred.train_generator(A, features)\n",
    "            loss.backward()\n",
    "            opt_gen.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f03c71d-ac62-46d8-890d-c0565c9be9ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "U = torch.rand(10,2)\n",
    "u = torch.rand(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b334f4e5-edcb-4967-959f-9b656dbf7668",
   "metadata": {},
   "outputs": [],
   "source": [
    "features.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd20684f-2485-4980-b22f-4315f64fa6e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e8a59f5-7fb5-4309-92ba-4f819bc541d9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:FEARFRED]",
   "language": "python",
   "name": "conda-env-FEARFRED-py"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
