# AUTOGENERATED! DO NOT EDIT! File to edit: ../../nbs/00b_Toy_Graph_Datasets.ipynb.

# %% auto 0
__all__ = ['visualize_graph', 'visualize_heatmap', 'display_gallery', 'display_graph_gallery', 'display_heatmap_gallery',
           'SmallRandom', 'SourceSink', 'ChainGraph', 'HalfChainGraph', 'CycleGraph', 'HalfCycleGraph']

# %% ../../nbs/00b_Toy_Graph_Datasets.ipynb 4
import matplotlib.pyplot as plt
import networkx as nx
from torch_geometric.utils import to_networkx
def visualize_graph(data, is_networkx=False, to_undirected=False, ax=None):
    G = data if is_networkx else to_networkx(data, to_undirected=to_undirected)
    pos = nx.spring_layout(G, seed=42)
    if ax is None:
        nx.draw_networkx(
            G, pos=pos, arrowsize=20, node_color="#adade0"
        )
        plt.show()
    else:
        nx.draw_networkx(
            G, pos=pos, arrowsize=20, node_color="#adade0", ax=ax
        )

# %% ../../nbs/00b_Toy_Graph_Datasets.ipynb 5
from torch_geometric.utils import to_dense_adj
def visualize_heatmap(edge_index, order_ind=None, cmap = "copper", ax=None):
    dense_adj = to_dense_adj(edge_index)[0]
    if order_ind is not None:
        dense_adj = dense_adj[order_ind, :][:, order_ind]
    if ax is not None:
        ax.imshow(dense_adj, cmap=cmap)
    else:
        plt.imshow(dense_adj, cmap=cmap)
        plt.show()

# %% ../../nbs/00b_Toy_Graph_Datasets.ipynb 6
def display_gallery(vizset, ncol=4):
    nviz = len(vizset)
    nrow = int(np.ceil(nviz/ncol))
    fig = plt.figure(figsize=(4*ncol, 3*nrow))
    for i, viz in enumerate(vizset):
        name, data, vizcall, is3d = viz
        ax = fig.add_subplot(nrow, ncol, i+1, projection="3d" if is3d else None)
        vizcall(data, ax)
        ax.set_title(name, y=1.0)

# %% ../../nbs/00b_Toy_Graph_Datasets.ipynb 7
def display_graph_gallery(dataset, ncol=4):
    vizset = []
    for name, data in dataset:
        vizset.append((name, data, lambda d, ax: visualize_graph(d, ax=ax), False))
    display_gallery(vizset, ncol)

# %% ../../nbs/00b_Toy_Graph_Datasets.ipynb 8
def display_heatmap_gallery(dataset, ncol=4):
    vizset = []
    for name, data in dataset:
        vizset.append((name, data, lambda data, ax: visualize_heatmap(
            data.edge_index, 
            order_ind=None if data.y is None else torch.argsort(data.y[:,-1]), 
            ax=ax
        ), False))
    display_gallery(vizset, ncol)

# %% ../../nbs/00b_Toy_Graph_Datasets.ipynb 10
import warnings
import torch
from torch_geometric.data import Data, InMemoryDataset
from torch_sparse import SparseTensor
from torch_geometric.utils import remove_self_loops

class SmallRandom(InMemoryDataset):
    # A dataset with random edges
    def __init__(self, num_nodes=5, prob_edge=0.2, transform=None, pre_transform=None):
        super().__init__(".", transform, pre_transform)

        if num_nodes > 300:
            num_nodes = 300
            warnings.warn(
                f"Number of nodes is too large for SmallRandom dataset. Reset num_nodes =  {num_nodes}"
            )

        dense_adj = (torch.rand((num_nodes, num_nodes)) < prob_edge).int()
        sparse_adj = SparseTensor.from_dense(dense_adj)
        row, col, _ = sparse_adj.coo()
        edge_index, _ = remove_self_loops(torch.stack([row, col]))

        x = torch.eye(num_nodes, dtype=torch.float)
        data = Data(x=x, edge_index=edge_index)
        if self.pre_transform is not None:
            data = self.pre_transform(data)
        self.data, self.slices = self.collate([data])

# %% ../../nbs/00b_Toy_Graph_Datasets.ipynb 16
import warnings
from torch_geometric.transforms import BaseTransform
from torch_geometric.utils import sort_edge_index


class SourceSink(BaseTransform):
    """
    Transform a (directed or undirected) graph into a directed graph
    with a proportion of the nodes with mostly out-edges
    and a porportion of the nodes with mostly in-edges

    Parameters
    ----------
    prob_source : float
        must be between 0 and 1
        Proportion of nodes/communities to turn into source nodes/communities
        (with mostly out-edges)
    prob_sink : float
        must be between 0 and 1
        prob_source and prob_sink must add up to no more than 1
        Proportion of nodes/communities to turn into sink nodes/communities
        (with mostly in-edges)
    adv_prob : float
        must be between 0 and 1
        Probability of in-edges for source nodes and/or out-edges for sink nodes
    remove_prob : float
        must be between 0 and 1
        Probability of removing an in-edge for source nodes and/or out-edges for sink nodes
        1 - remove_prob is the probability of reversing the direction of in-edge for source nodes and/or out-edges for sink nodes
    """

    def __init__(self, prob_source=0.1, prob_sink=0.1, adv_prob=0, remove_prob=0):
        if prob_source + prob_sink > 1:
            warnings.warn("Total probability of source and sink exceeds 1")
            excess = prob_source + prob_sink - 1
            prob_source -= excess / 2
            prob_sink -= excess / 2
            warnings.warn(
                f"Adjusted: prob_source = {prob_source}, prob_sink = {prob_sink}"
            )
        self.prob_source = prob_source
        self.prob_sink = prob_sink
        self.adv_prob = adv_prob
        self.remove_prob = remove_prob

    def _has_ground_truth(self, data):
        return data.y is not None and data.y.shape == (data.num_nodes, 2)

    def _wrong_direction(self, labels, sources, sinks, tail, head):
        return (labels[head] in sources and labels[tail] not in sources) or (
            labels[tail] in sinks and labels[head] not in sinks
        )

    def __call__(self, data):
        if self._has_ground_truth(data):
            # get ground truth labels
            y = data.y[torch.argsort(data.y[:, 0]), :]
            classes = y[:, 1].unique()
            # randomly choose source and sink classes
            mask = torch.rand(len(classes))
            source_classes = classes[mask < self.prob_source]
            sink_classes = classes[mask > 1 - self.prob_sink]
            # add source/sink ground-truth label
            y = torch.hstack(
                (
                    y,
                    torch.t(
                        torch.tensor(
                            [
                                [
                                    1
                                    if c in source_classes
                                    else -1
                                    if c in sink_classes
                                    else 0
                                    for c in y[:, 1]
                                ]
                            ]
                        )
                    ),
                )
            )
            labels = y[:, 1]
            sources = source_classes
            sinks = sink_classes
        else:
            warnings.warn("Data has no ground-truth labels")
            # randomly choose source and sink nodes
            nodes = torch.arange(data.num_nodes)
            mask = torch.rand(data.num_nodes)
            source_nodes = nodes[mask < self.prob_source]
            sink_nodes = nodes[mask > 1 - self.prob_sink]
            # add source/sink ground-truth label
            y = torch.tensor(
                [
                    [n, 1 if n in source_nodes else -1 if n in sink_nodes else 0]
                    for n in nodes
                ]
            )
            labels = nodes
            sources = source_nodes
            sinks = sink_nodes

        # correct improper edges
        edge_array = []
        for e in range(data.num_edges):
            tail, head = data.edge_index[:, e]
            if (
                self._wrong_direction(labels, sources, sinks, tail, head)
                and torch.rand(1)[0] > self.adv_prob
            ):
                if torch.rand(1)[0] < self.remove_prob:  # remove the improper edge
                    continue
                else:  # reverse the improper edge
                    edge_array.append([head, tail])
            else:  # keep proper edge
                edge_array.append([tail, head])
        edge_index = torch.t(torch.tensor(edge_array))
        data.edge_index = sort_edge_index(edge_index)
        data.y = y
        return data.coalesce()

# %% ../../nbs/00b_Toy_Graph_Datasets.ipynb 22
class ChainGraph(InMemoryDataset):
    def __init__(self, num_nodes=5, transform=None):
        super().__init__(".", transform)
        dense_adj = torch.diag(torch.ones(num_nodes-1), 1)
        sparse_adj = SparseTensor.from_dense(dense_adj)
        row, col, _ = sparse_adj.coo()
        edge_index, _ = remove_self_loops(torch.stack([row, col]))

        x = torch.eye(num_nodes, dtype=torch.float)
        data = Data(x=x, edge_index=edge_index)
        self.data, self.slices = self.collate([data])

# %% ../../nbs/00b_Toy_Graph_Datasets.ipynb 24
class HalfChainGraph(InMemoryDataset):
    def __init__(self, num_nodes=3, center=1, transform=None):
        super().__init__(".", transform)
        dense_adj = (
            torch.diag(torch.cat((torch.ones(center), torch.zeros(num_nodes-center-1))), 1)
            + torch.diag(torch.cat((torch.zeros(center), torch.ones(num_nodes-center-1))), -1)
        )
        sparse_adj = SparseTensor.from_dense(dense_adj)
        row, col, _ = sparse_adj.coo()
        edge_index, _ = remove_self_loops(torch.stack([row, col]))

        x = torch.eye(num_nodes, dtype=torch.float)
        data = Data(x=x, edge_index=edge_index)
        self.data, self.slices = self.collate([data])

# %% ../../nbs/00b_Toy_Graph_Datasets.ipynb 26
class CycleGraph(InMemoryDataset):
    def __init__(self, num_nodes=8, transform=None):
        super().__init__(".", transform)
        dense_adj = torch.diag(torch.ones(num_nodes-1), 1)
        dense_adj[num_nodes-1,0] = 1
        sparse_adj = SparseTensor.from_dense(dense_adj)
        row, col, _ = sparse_adj.coo()
        edge_index, _ = remove_self_loops(torch.stack([row, col]))

        x = torch.eye(num_nodes, dtype=torch.float)
        data = Data(x=x, edge_index=edge_index)
        self.data, self.slices = self.collate([data])

# %% ../../nbs/00b_Toy_Graph_Datasets.ipynb 28
class HalfCycleGraph(InMemoryDataset):
    def __init__(self, num_nodes=3, center=0, transform=None):
        super().__init__(".", transform)
        dense_adj = torch.diag(torch.ones(num_nodes-1), 1)
        dense_adj[num_nodes-1,0] = 1
        dense_adj[(center+1)%num_nodes, center] = 1
        sparse_adj = SparseTensor.from_dense(dense_adj)
        row, col, _ = sparse_adj.coo()
        edge_index, _ = remove_self_loops(torch.stack([row, col]))

        x = torch.eye(num_nodes, dtype=torch.float)
        data = Data(x=x, edge_index=edge_index)
        self.data, self.slices = self.collate([data])
