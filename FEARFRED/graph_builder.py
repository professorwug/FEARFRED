# AUTOGENERATED! DO NOT EDIT! File to edit: ../nbs/GraphBuilder.ipynb.

# %% auto 0
__all__ = ['directions_array_from', 'flashlight_cosine_similarity', 'anisotropic_kernel', 'adaptive_anisotropic_kernel',
           'flashlight_kernel']

# %% ../nbs/GraphBuilder.ipynb 3
def directions_array_from(X):
    """Given n x d tensor X, returns n x n tensor where entry i,j is x_j - x_i. Useful for getting a distance matrix."""
    n1 = X.shape[0]
    P2 = X[:, :, None].repeat(1, 1, n1)
    P1 = X.T.repeat(n1, 1, 1)
    P3 = P1 - P2
    P3 = P3.transpose(1, 2)
    return P3
def flashlight_cosine_similarity(X, flow, directions_array = None, eps = 0.01):
    """Computes a localized cosine similarity between the direction xj - xi and the flow at xi. Ideal for use in embedding spaces."""
    # Get directions array of xj - xi
    if directions_array is not None:
        P3 = directions_array
    else:
        P3 = directions_array_from(X)
    # expand array of flows
    flows_expanded = flow.repeat(len(X),1,1).transpose(dim0=0,dim1=1)
    # get norms of each array
    norm_flows = torch.linalg.norm(flows_expanded,dim=2)
    norm_directions = torch.linalg.norm(P3,dim=2)
    # Perform dot product
    dot_prod = (P3 * flows_expanded).sum(dim=2)
    # normalize by norms
    cosine_sim = dot_prod / (torch.max(torch.tensor(eps),norm_flows * norm_directions))
    return cosine_sim


# %% ../nbs/GraphBuilder.ipynb 8
import torch
import numpy as np
def anisotropic_kernel(D, sigma=0.7, alpha = 1):
    """Computes anisotropic kernel of given distances matrix.

    Parameters
    ----------
    D : ndarray or sparse
    sigma : float, optional
      Kernel bandwidth, by default 0.7
    alpha : int, optional
      Degree of density normalization, from 0 to 1; by default 1
    This is a good function.
    """
    W = torch.exp(-D**2/(2*sigma**2))
    # Additional normalization step for density
    D = torch.diag(1/(torch.sum(W,dim=1)**alpha)) 
    W = D @ W @ D
    return W
def adaptive_anisotropic_kernel(D, k=10, alpha = 1):
    # Get the distance to the kth neighbor
    distance_to_k_neighbor = np.partition(D,k)[:,k]
    # Populate matrices with this distance for easy division. 
    div1 = np.ones(len(D))[:,None] @ distance_to_k_neighbor[None,:]
    div2 = div1.T
    # compute the gaussian kernel with an adaptive bandwidth
    W = (1/2*np.sqrt(2*np.pi))*(np.exp(-D**2/(2*div1**2))/div1 + np.exp(-D**2/(2*div2**2))/div2)
    # Additional normalization step for density
    D = np.diag(1/(np.sum(W,axis=1)**alpha)) 
    W = D @ W @ D
    return W

# %% ../nbs/GraphBuilder.ipynb 9
import torch
def flashlight_kernel(X, flows, kernel_type = "fixed", k=10, sigma = 0.7, anisotropic_density_normalization = 1, flow_strength=1):
    """A distance aware adaptation of the flashlight cosine similarity, 
    obtained by multiplying the cosine similarity by a traditional guassian kernel.
    This is not intended to be differentiable, although is with some choices of kernels (anisotropic, plain).
    """
    # Get flashlight cosine
    DA = directions_array_from(X)
    W_cosine = flashlight_cosine_similarity(X, flows, directions_array=DA)
    # Flow strength must be an odd integer to be symmetric
    assert flow_strength == int(flow_strength) and flow_strength // 2 != flow_strength /2
    W_strengthened_cosine = W_cosine ** flow_strength
    D = torch.linalg.norm(DA, dim=-1)
    if kernel_type == "anisotropic":
        W = anisotropic_kernel(D, sigma=sigma, alpha=anisotropic_density_normalization) # works with pytorch tensors, is theoretically differentiable.
    if kernel_type == "adaptive anisotropic":
        D_np = D.numpy()
        W_np = adaptive_anisotropic_kernel(D_np, k=k, alpha = anisotropic_density_normalization)
        W = torch.tensor(W_np)
    if kernel_type == "fixed":
        W = (1/((2*torch.pi)**0.5*sigma))*torch.exp(-D/(2*sigma**2))
        W = W.fill_diagonal_(0)
    flashlight_K = W * torch.exp(W_strengthened_cosine-1)
    return flashlight_K
